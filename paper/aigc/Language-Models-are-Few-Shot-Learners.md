

2020年5月，OpenAI发表《Language Models are Few-Shot Learners》，呈现GPT-3。GPT-3 比 GPT-2 
大 100 倍，它拥有1750 亿个参数。然而，它与其他 GPT 并没有本质不同，基本原则大体一致。尽管 GPT 模型之
间的相似性很高，但 GPT-3 的性能仍超出了所有可能的预期.