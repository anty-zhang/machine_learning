
# 神经网络可解释性

## KNOWLEDGE CONSISTENCY BETWEEN NEURAL NETWORKS AND BEYOND

对神经网络的理解可以分为两个部分:

- 语义层面。 通过可视化神经网络的中层特征。发现，简单特征往往表示物体的主体形状；而复杂特征往往是一些细节、噪声。

- 数学推导层面。从数学层面，对各个角度推导出神经网络表达的边界。

然而，这两类解释性研究往往各自为战，语义层面的解释往往缺乏坚实的理论支撑，数学层面的推导又难以对接到人的认知，让人真正地理解神经网络。

[ICML2021 | 可解释性：对神经网络中层特征复杂度的解释与拆分](https://cloud.tencent.com/developer/article/1878315)

[KNOWLEDGE CONSISTENCY BETWEEN NEURAL NETWORKS AND BEYOND](https://arxiv.org/pdf/1908.01581.pdf)

## 图神经网络可解释性

[Explainability in Graph Neural Networks: A Taxonomic Survey](https://arxiv.org/pdf/2012.15445.pdf)


## 其它论文

[神经网络的可解释性：最新论文列表](https://zhuanlan.zhihu.com/p/74542589)


